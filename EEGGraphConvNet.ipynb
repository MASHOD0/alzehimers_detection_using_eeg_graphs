{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGGraphConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, global_add_pool, ChebConv, global_max_pool, SAGPooling, GATConv, GATv2Conv, TransformerConv, SuperGATConv, global_mean_pool, Linear\n",
    "from torch.nn import BatchNorm1d\n",
    "from math import floor\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGGraphConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, reduced_sensors=True, sfreq=None, batch_size=64):\n",
    "        super(EEGGraphConvNet, self).__init__()\n",
    "        # Define and initialize hyperparameters\n",
    "        self.sfreq = sfreq\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = 153550\n",
    "        \n",
    "        # Layers definition\n",
    "        # Graph convolutional layers\n",
    "        self.conv1 = GCNConv(self.input_size, 16, cached=True, normalize=False)\n",
    "        self.conv2 = GCNConv(16, 32, cached=True, normalize=False)\n",
    "        self.conv3 = GCNConv(32, 64, cached=True, normalize=False)\n",
    "        self.conv4 = GCNConv(64, 50, cached=True, normalize=False)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.batch_norm = BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(50, 30)\n",
    "        self.fc2 = nn.Linear(30, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "        \n",
    "        # Xavier initializacion for fully connected layers\n",
    "        self.fc1.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if isinstance(x, nn.Linear) else None)\n",
    "        self.fc2.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if isinstance(x, nn.Linear) else None)\n",
    "        self.fc3.apply(lambda x: nn.init.xavier_normal_(x.weight, gain=1) if isinstance(x, nn.Linear) else None)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weigth, batch):\n",
    "        # Perform all graph convolutions\n",
    "        x = F.leaky_relu(self.conv1(x, edge_index, edge_weigth), negative_slope=0.01)\n",
    "        #x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv2(x, edge_index, edge_weigth), negative_slope=0.01)\n",
    "        #x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        x = F.leaky_relu(self.conv3(x, edge_index, edge_weigth), negative_slope=0.01)\n",
    "        #x = F.dropout(x, p=0.2, training=self.training)\n",
    "        \n",
    "        conv_out = self.conv4(x, edge_index, edge_weigth)\n",
    "        # Perform batch normalization\n",
    "        batch_norm_out = F.leaky_relu(self.batch_norm(conv_out), negative_slope=0.01)\n",
    "        #x = F.dropout(batch_norm_out, p=0.2, training=self.training)\n",
    "        \n",
    "        # Global add pooling\n",
    "        mean_pool = global_add_pool(batch_norm_out, batch=batch)\n",
    "        \n",
    "        # Apply fully connected layters\n",
    "        out = F.leaky_relu(self.fc1(mean_pool), negative_slope=0.01)\n",
    "        #out = F.dropout(out, p = 0.2, training=self.training)\n",
    "        \n",
    "        out = F.leaky_relu(self.fc2(out), negative_slope=0.01)\n",
    "        #out = F.dropout(out, p = 0.2, training=self.training)\n",
    "        \n",
    "        out = F.leaky_relu(self.fc3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corrected_data_list(path):\n",
    "    data_list = list()\n",
    "    for file in path.iterdir():\n",
    "        data_list.append(torch.load(file))\n",
    "    corrected_data_list = list()\n",
    "    for data in data_list:\n",
    "    # print(data)\n",
    "        data = torch_geometric.data.Data(\n",
    "            x=torch.tensor(data.x),\n",
    "            edge_index=torch.tensor(data.edge_index),\n",
    "            edge_attr=torch.tensor(data.edge_attr),\n",
    "            label=torch.tensor(data.label),\n",
    "        )\n",
    "        corrected_data_list.append(data)\n",
    "       \n",
    "       \n",
    "    rm = [\n",
    "      7,\n",
    "      14+1,\n",
    "      14+2,\n",
    "      17+3,\n",
    "      17+4,\n",
    "      26+5,\n",
    "      38+6,\n",
    "      54+7,\n",
    "      65+8,\n",
    "      69+9\n",
    "      ]\n",
    "\n",
    "    dl = list()\n",
    "    start = 0\n",
    "    for r in rm:\n",
    "        dl.extend(corrected_data_list[start:r])\n",
    "        start = r + 1\n",
    "\n",
    "    dl.extend(corrected_data_list[start:])\n",
    "    dl_filterd = list()\n",
    "    for data in dl:\n",
    "        if data.label == 2:\n",
    "            # print(data.label)\n",
    "            # if data.label == 2:\n",
    "            data.label = torch.tensor(1)\n",
    "        dl_filterd.append(data)\n",
    "\n",
    "    len(dl_filterd)\n",
    "    return dl_filterd\n",
    "\n",
    "def print_classification_report(y_pred, y_true):\n",
    "    print(classification_report(y_true, y_pred))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge :: Pearson Node:: Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(data.edge_index),\n"
     ]
    }
   ],
   "source": [
    "path = Path('graphs/moments_pearson/')\n",
    "dl_filterd = create_corrected_data_list(path)\n",
    "train_dl, test_dl = train_test_split(dl_filterd, test_size=0.2, random_state=47744)\n",
    "train_dataloader = torch_geometric.loader.DataLoader(dl_filterd, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch_geometric.loader.DataLoader(test_dl, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGGraphConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params: 8310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EEGGraphConvNet(\n",
       "  (conv1): GCNConv(6, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (conv3): GCNConv(32, 64)\n",
       "  (conv4): GCNConv(64, 50)\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Params: {sum(p.numel() for p in model.parameters())}\")\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : epoch=1\t loss=5.978604\t acc=0.512821\n",
      "Test  : epoch=1\t loss=21.733632\t acc=0.500000\n",
      "\n",
      "Train : epoch=2\t loss=3.378997\t acc=0.653846\n",
      "Test  : epoch=2\t loss=28.055350\t acc=0.500000\n",
      "\n",
      "Train : epoch=3\t loss=4.219826\t acc=0.653846\n",
      "Test  : epoch=3\t loss=37.163696\t acc=0.500000\n",
      "\n",
      "Train : epoch=4\t loss=3.723499\t acc=0.653846\n",
      "Test  : epoch=4\t loss=41.898043\t acc=0.500000\n",
      "\n",
      "Train : epoch=5\t loss=3.558074\t acc=0.653846\n",
      "Test  : epoch=5\t loss=25.975524\t acc=0.500000\n",
      "\n",
      "Train : epoch=6\t loss=3.503170\t acc=0.653846\n",
      "Test  : epoch=6\t loss=35.321392\t acc=0.500000\n",
      "\n",
      "Train : epoch=7\t loss=3.588062\t acc=0.653846\n",
      "Test  : epoch=7\t loss=19.714920\t acc=0.500000\n",
      "\n",
      "Train : epoch=8\t loss=3.625276\t acc=0.653846\n",
      "Test  : epoch=8\t loss=20.688565\t acc=0.500000\n",
      "\n",
      "Train : epoch=9\t loss=3.559157\t acc=0.653846\n",
      "Test  : epoch=9\t loss=5.936975\t acc=0.500000\n",
      "\n",
      "Train : epoch=10\t loss=3.506320\t acc=0.653846\n",
      "Test  : epoch=10\t loss=19.151947\t acc=0.500000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = False\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    \n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        #print(out.shape)\n",
    "        # print(data.label)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        acc = (out.argmax(dim=1) == data.label).sum().item() / len(data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "        # print(f'{count=}{out}')\n",
    "        # print(out.argmax(dim=1), data.label, end=' ')\n",
    "        if verbose: print(f\"epoch={epoch}\\t batch={idx+1} : loss={loss.item():.6f}\\t acc={acc:.6f}\", end='\\n')\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
    "        optimizer.step()\n",
    "        # break\n",
    "        count += 1\n",
    "    print(f\"Train : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n')\n",
    "\n",
    "    model.eval()\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data[0]=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "    \n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out.edge_attr)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        # print(out)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "\n",
    "    print(f\"Test  : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.50      1.00      0.67         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moments PLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(data.edge_index),\n"
     ]
    }
   ],
   "source": [
    "path = Path('graphs/moments_pli/')\n",
    "dl_filterd = create_corrected_data_list(path)\n",
    "train_dl, test_dl = train_test_split(dl_filterd, test_size=0.2, random_state=47744)\n",
    "train_dataloader = torch_geometric.loader.DataLoader(dl_filterd, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch_geometric.loader.DataLoader(test_dl, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params: 8310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EEGGraphConvNet(\n",
       "  (conv1): GCNConv(6, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (conv3): GCNConv(32, 64)\n",
       "  (conv4): GCNConv(64, 50)\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EEGGraphConvNet()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Params: {sum(p.numel() for p in model.parameters())}\")\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : epoch=1\t loss=3.639596\t acc=0.500000\n",
      "Test  : epoch=1\t loss=5.950003\t acc=0.500000\n",
      "\n",
      "Train : epoch=2\t loss=3.695385\t acc=0.653846\n",
      "Test  : epoch=2\t loss=26.947660\t acc=0.625000\n",
      "\n",
      "Train : epoch=3\t loss=3.737758\t acc=0.653846\n",
      "Test  : epoch=3\t loss=54.829233\t acc=0.500000\n",
      "\n",
      "Train : epoch=4\t loss=3.672758\t acc=0.653846\n",
      "Test  : epoch=4\t loss=54.867120\t acc=0.500000\n",
      "\n",
      "Train : epoch=5\t loss=3.574434\t acc=0.653846\n",
      "Test  : epoch=5\t loss=30.195161\t acc=0.500000\n",
      "\n",
      "Train : epoch=6\t loss=3.443010\t acc=0.653846\n",
      "Test  : epoch=6\t loss=26.508394\t acc=0.500000\n",
      "\n",
      "Train : epoch=7\t loss=3.665242\t acc=0.653846\n",
      "Test  : epoch=7\t loss=82.827342\t acc=0.500000\n",
      "\n",
      "Train : epoch=8\t loss=3.572275\t acc=0.653846\n",
      "Test  : epoch=8\t loss=22.204983\t acc=0.500000\n",
      "\n",
      "Train : epoch=9\t loss=3.539030\t acc=0.653846\n",
      "Test  : epoch=9\t loss=30.702687\t acc=0.500000\n",
      "\n",
      "Train : epoch=10\t loss=3.534097\t acc=0.653846\n",
      "Test  : epoch=10\t loss=42.896651\t acc=0.500000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = False\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    \n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        #print(out.shape)\n",
    "        # print(data.label)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        acc = (out.argmax(dim=1) == data.label).sum().item() / len(data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "        # print(f'{count=}{out}')\n",
    "        # print(out.argmax(dim=1), data.label, end=' ')\n",
    "        if verbose: print(f\"epoch={epoch}\\t batch={idx+1} : loss={loss.item():.6f}\\t acc={acc:.6f}\", end='\\n')\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
    "        optimizer.step()\n",
    "        # break\n",
    "        count += 1\n",
    "    print(f\"Train : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n')\n",
    "\n",
    "    model.eval()\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data[0]=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "    \n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out.edge_attr)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        # print(out)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        \n",
    "        y_true.extend(data.label.tolist())\n",
    "\n",
    "    print(f\"Test  : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.50      1.00      0.67         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(y_pred, y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSD CSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(data.edge_index),\n"
     ]
    }
   ],
   "source": [
    "path = Path('graphs/psd_csd/')\n",
    "dl_filterd = create_corrected_data_list(path)\n",
    "train_dl, test_dl = train_test_split(dl_filterd, test_size=0.2, random_state=47744)\n",
    "train_dataloader = torch_geometric.loader.DataLoader(dl_filterd, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch_geometric.loader.DataLoader(test_dl, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGGraphConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params: 8310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EEGGraphConvNet(\n",
       "  (conv1): GCNConv(6, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (conv3): GCNConv(32, 64)\n",
       "  (conv4): GCNConv(64, 50)\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Params: {sum(p.numel() for p in model.parameters())}\")\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : epoch=1\t loss=0.738278\t acc=0.653846\n",
      "Test  : epoch=1\t loss=0.706056\t acc=0.500000\n",
      "\n",
      "Train : epoch=2\t loss=0.928931\t acc=0.653846\n",
      "Test  : epoch=2\t loss=0.916596\t acc=0.500000\n",
      "\n",
      "Train : epoch=3\t loss=1.595207\t acc=0.653846\n",
      "Test  : epoch=3\t loss=1.592788\t acc=0.500000\n",
      "\n",
      "Train : epoch=4\t loss=3.031802\t acc=0.653846\n",
      "Test  : epoch=4\t loss=3.482221\t acc=0.500000\n",
      "\n",
      "Train : epoch=5\t loss=3.326565\t acc=0.653846\n",
      "Test  : epoch=5\t loss=3.629290\t acc=0.500000\n",
      "\n",
      "Train : epoch=6\t loss=3.314263\t acc=0.653846\n",
      "Test  : epoch=6\t loss=3.632210\t acc=0.500000\n",
      "\n",
      "Train : epoch=7\t loss=3.307780\t acc=0.653846\n",
      "Test  : epoch=7\t loss=3.642444\t acc=0.500000\n",
      "\n",
      "Train : epoch=8\t loss=3.303494\t acc=0.653846\n",
      "Test  : epoch=8\t loss=3.646749\t acc=0.500000\n",
      "\n",
      "Train : epoch=9\t loss=3.299511\t acc=0.653846\n",
      "Test  : epoch=9\t loss=3.652948\t acc=0.500000\n",
      "\n",
      "Train : epoch=10\t loss=3.295911\t acc=0.653846\n",
      "Test  : epoch=10\t loss=3.658892\t acc=0.500000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = False\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    \n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        #print(out.shape)\n",
    "        # print(data.label)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        acc = (out.argmax(dim=1) == data.label).sum().item() / len(data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "        # print(f'{count=}{out}')\n",
    "        # print(out.argmax(dim=1), data.label, end=' ')\n",
    "        if verbose: print(f\"epoch={epoch}\\t batch={idx+1} : loss={loss.item():.6f}\\t acc={acc:.6f}\", end='\\n')\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
    "        optimizer.step()\n",
    "        # break\n",
    "        count += 1\n",
    "    print(f\"Train : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n')\n",
    "\n",
    "    model.eval()\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data[0]=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "    \n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out.edge_attr)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        # print(out)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "\n",
    "    print(f\"Test  : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.50      1.00      0.67         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSD Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(data.edge_index),\n"
     ]
    }
   ],
   "source": [
    "path = Path('graphs/psd_pearson/')\n",
    "dl_filterd = create_corrected_data_list(path)\n",
    "train_dl, test_dl = train_test_split(dl_filterd, test_size=0.2, random_state=47744)\n",
    "train_dataloader = torch_geometric.loader.DataLoader(dl_filterd, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch_geometric.loader.DataLoader(test_dl, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGGraphConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params: 2465014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EEGGraphConvNet(\n",
       "  (conv1): GCNConv(153550, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (conv3): GCNConv(32, 64)\n",
       "  (conv4): GCNConv(64, 50)\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Params: {sum(p.numel() for p in model.parameters())}\")\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (19x6 and 153550x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# out = model(x=data.x, edge_index=data.edge_index)\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weigth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# print(out)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# print(f\"{out.shape=}\")\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#print(out.shape)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# print(data.label)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39mlabel)\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[66], line 32\u001b[0m, in \u001b[0;36mEEGGraphConvNet.forward\u001b[1;34m(self, x, edge_index, edge_weigth, batch)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_weigth, batch):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Perform all graph convolutions\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weigth\u001b[49m\u001b[43m)\u001b[49m, negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m#x = F.dropout(x, p=0.2, training=self.training)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_weigth), negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m             edge_index \u001b[38;5;241m=\u001b[39m cache\n\u001b[1;32m--> 241\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m    244\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight,\n\u001b[0;32m    245\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:130\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (19x6 and 153550x16)"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = False\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    \n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        #print(out.shape)\n",
    "        # print(data.label)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        acc = (out.argmax(dim=1) == data.label).sum().item() / len(data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "        # print(f'{count=}{out}')\n",
    "        # print(out.argmax(dim=1), data.label, end=' ')\n",
    "        if verbose: print(f\"epoch={epoch}\\t batch={idx+1} : loss={loss.item():.6f}\\t acc={acc:.6f}\", end='\\n')\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
    "        optimizer.step()\n",
    "        # break\n",
    "        count += 1\n",
    "    print(f\"Train : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n')\n",
    "\n",
    "    model.eval()\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data[0]=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "    \n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out.edge_attr)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        # print(out)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "\n",
    "    print(f\"Test  : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.50      1.00      0.67         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x=torch.tensor(data.x),\n",
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(data.edge_index),\n"
     ]
    }
   ],
   "source": [
    "path = Path('graphs/raw_pearson/')\n",
    "dl_filterd = create_corrected_data_list(path)\n",
    "train_dl, test_dl = train_test_split(dl_filterd, test_size=0.2, random_state=47744)\n",
    "train_dataloader = torch_geometric.loader.DataLoader(dl_filterd, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch_geometric.loader.DataLoader(test_dl, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGGraphConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params: 2465014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EEGGraphConvNet(\n",
       "  (conv1): GCNConv(153550, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (conv3): GCNConv(32, 64)\n",
       "  (conv4): GCNConv(64, 50)\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Params: {sum(p.numel() for p in model.parameters())}\")\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : epoch=1\t loss=4.052598\t acc=0.487179\n",
      "Test  : epoch=1\t loss=0.971192\t acc=0.250000\n",
      "\n",
      "Train : epoch=2\t loss=3.781555\t acc=0.653846\n",
      "Test  : epoch=2\t loss=14.769562\t acc=0.500000\n",
      "\n",
      "Train : epoch=3\t loss=4.065837\t acc=0.653846\n",
      "Test  : epoch=3\t loss=8.457732\t acc=0.500000\n",
      "\n",
      "Train : epoch=4\t loss=3.725933\t acc=0.653846\n",
      "Test  : epoch=4\t loss=11.927264\t acc=0.500000\n",
      "\n",
      "Train : epoch=5\t loss=3.437182\t acc=0.653846\n",
      "Test  : epoch=5\t loss=11.956793\t acc=0.562500\n",
      "\n",
      "Train : epoch=6\t loss=4.645468\t acc=0.448718\n",
      "Test  : epoch=6\t loss=28.408250\t acc=0.375000\n",
      "\n",
      "Train : epoch=7\t loss=3.240787\t acc=0.641026\n",
      "Test  : epoch=7\t loss=18.953414\t acc=0.500000\n",
      "\n",
      "Train : epoch=8\t loss=3.645335\t acc=0.653846\n",
      "Test  : epoch=8\t loss=27.227204\t acc=0.500000\n",
      "\n",
      "Train : epoch=9\t loss=3.532817\t acc=0.653846\n",
      "Test  : epoch=9\t loss=29.669804\t acc=0.500000\n",
      "\n",
      "Train : epoch=10\t loss=3.424646\t acc=0.653846\n",
      "Test  : epoch=10\t loss=22.872963\t acc=0.500000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = False\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    \n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        #print(out.shape)\n",
    "        # print(data.label)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        acc = (out.argmax(dim=1) == data.label).sum().item() / len(data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "        # print(f'{count=}{out}')\n",
    "        # print(out.argmax(dim=1), data.label, end=' ')\n",
    "        if verbose: print(f\"epoch={epoch}\\t batch={idx+1} : loss={loss.item():.6f}\\t acc={acc:.6f}\", end='\\n')\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
    "        optimizer.step()\n",
    "        # break\n",
    "        count += 1\n",
    "    print(f\"Train : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n')\n",
    "\n",
    "    model.eval()\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data[0]=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "    \n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out.edge_attr)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        # print(out)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "\n",
    "    print(f\"Test  : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.50      1.00      0.67         8\n",
      "\n",
      "    accuracy                           0.50        16\n",
      "   macro avg       0.25      0.50      0.33        16\n",
      "weighted avg       0.25      0.50      0.33        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\mashh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw PLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x=torch.tensor(data.x),\n",
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_25072\\114600516.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_index=torch.tensor(data.edge_index),\n"
     ]
    }
   ],
   "source": [
    "path = Path('graphs/raw_pli/')\n",
    "dl_filterd = create_corrected_data_list(path)\n",
    "train_dl, test_dl = train_test_split(dl_filterd, test_size=0.2, random_state=47744)\n",
    "train_dataloader = torch_geometric.loader.DataLoader(dl_filterd, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_dataloader = torch_geometric.loader.DataLoader(test_dl, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EEGGraphConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Params: 2465014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EEGGraphConvNet(\n",
       "  (conv1): GCNConv(153550, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (conv3): GCNConv(32, 64)\n",
       "  (conv4): GCNConv(64, 50)\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Params: {sum(p.numel() for p in model.parameters())}\")\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : epoch=1\t loss=2.914385\t acc=0.525641\n",
      "Test  : epoch=1\t loss=176954.454613\t acc=0.437500\n",
      "\n",
      "Train : epoch=2\t loss=3.409859\t acc=0.653846\n",
      "Test  : epoch=2\t loss=380303.394798\t acc=0.500000\n",
      "\n",
      "Train : epoch=3\t loss=3.372157\t acc=0.653846\n",
      "Test  : epoch=3\t loss=376153.212579\t acc=0.500000\n",
      "\n",
      "Train : epoch=4\t loss=3.166202\t acc=0.653846\n",
      "Test  : epoch=4\t loss=306383.001804\t acc=0.500000\n",
      "\n",
      "Train : epoch=5\t loss=3.147335\t acc=0.653846\n",
      "Test  : epoch=5\t loss=280632.229725\t acc=0.500000\n",
      "\n",
      "Train : epoch=6\t loss=3.249767\t acc=0.653846\n",
      "Test  : epoch=6\t loss=380288.491279\t acc=0.500000\n",
      "\n",
      "Train : epoch=7\t loss=3.253895\t acc=0.653846\n",
      "Test  : epoch=7\t loss=324545.428888\t acc=0.500000\n",
      "\n",
      "Train : epoch=8\t loss=3.431442\t acc=0.653846\n",
      "Test  : epoch=8\t loss=475571.569723\t acc=0.500000\n",
      "\n",
      "Train : epoch=9\t loss=3.521528\t acc=0.653846\n",
      "Test  : epoch=9\t loss=311656.751135\t acc=0.500000\n",
      "\n",
      "Train : epoch=10\t loss=3.802683\t acc=0.653846\n",
      "Test  : epoch=10\t loss=355779.272687\t acc=0.437500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = False\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    \n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    for idx, data in enumerate(train_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        #print(out.shape)\n",
    "        # print(data.label)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        acc = (out.argmax(dim=1) == data.label).sum().item() / len(data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "        # print(f'{count=}{out}')\n",
    "        # print(out.argmax(dim=1), data.label, end=' ')\n",
    "        if verbose: print(f\"epoch={epoch}\\t batch={idx+1} : loss={loss.item():.6f}\\t acc={acc:.6f}\", end='\\n')\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
    "        optimizer.step()\n",
    "        # break\n",
    "        count += 1\n",
    "    print(f\"Train : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n')\n",
    "\n",
    "    model.eval()\n",
    "    losses, y_true, y_pred = list(), list(), list()\n",
    "    for idx, data in enumerate(test_dataloader):\n",
    "        # data = data[0]\n",
    "        # print(f\"{data[0]=}\")\n",
    "        # print(f\"{data.x.shape}\")\n",
    "    \n",
    "        \n",
    "        # out = model(x=data.x, edge_index=data.edge_index)\n",
    "        out = model(x=data.x, edge_index=data.edge_index, edge_weigth=data.edge_attr, batch=data.batch)\n",
    "        # print(out.edge_attr)\n",
    "        # print(f\"{out.shape=}\")\n",
    "        # print(out)\n",
    "\n",
    "        loss = criterion(out, data.label)\n",
    "        losses.append(loss.item())\n",
    "        y_pred.extend(out.argmax(dim=1).tolist())\n",
    "        y_true.extend(data.label.tolist())\n",
    "\n",
    "    print(f\"Test  : epoch={epoch}\\t loss={sum(losses)/len(losses):.6f}\\t acc={accuracy_score(y_true, y_pred):.6f}\", end='\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         8\n",
      "           1       0.47      0.88      0.61         8\n",
      "\n",
      "    accuracy                           0.44        16\n",
      "   macro avg       0.23      0.44      0.30        16\n",
      "weighted avg       0.23      0.44      0.30        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_classification_report(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
